{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tun/anaconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "thai_characters = [ '', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'เ', 'แ', 'โ', 'ใ', 'ไ', '็', '่', '้', '๊', '๋', '์']\n",
    "\n",
    "def get_name_indices(name):\n",
    "    name_indices= []\n",
    "    for c in name:\n",
    "        try:\n",
    "            i = thai_characters.index(c)\n",
    "        except ValueError as e:\n",
    "            i = 999\n",
    "\n",
    "        name_indices.append(i)\n",
    "        \n",
    "    return name_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "females = open('./data/female.txt', 'r').read().split(\"\\n\")\n",
    "males = open('./data/male.txt', 'r').read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female: 2946 | male: 1953\n"
     ]
    }
   ],
   "source": [
    "print('female: {} | male: {}'.format(len(females), len(males)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female: 2759 | male: 1870\n"
     ]
    }
   ],
   "source": [
    "females = list(set(females))\n",
    "males = list(set(males))\n",
    "print('female: {} | male: {}'.format(len(females), len(males)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest name chars female: 12 | male: 13\n"
     ]
    }
   ],
   "source": [
    "print('longest name chars female: {} | male: {}'.format(max(map(len, females)), max(map(len, males))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_female = list(map(get_name_indices, females))\n",
    "X_male = list(map(get_name_indices, males))\n",
    "Y_female = np.full(len(females), 0).tolist()\n",
    "Y_male = np.full(len(males), 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_female + X_male\n",
    "Y = Y_female + Y_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 15\n",
    "X = pad_sequences(X, padding='post', maxlen=maxlen, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 54, 60, 35, 35, 47, 21, 25, 66,  0,  0,  0,  0,  0,  0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=420)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=904)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_118 (Embedding)    (None, 15, 200)           13400     \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 15, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 11, 256)           256256    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 598,721\n",
      "Trainable params: 598,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(thai_characters), \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(filters=256,\n",
    "                 kernel_size=5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(filters=128,\n",
    "                 kernel_size=2,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 15, 200)           13400     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 15, 200)           0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 15, 256)           51456     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 15, 256)           65792     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 15, 64)            16448     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 961       \n",
      "=================================================================\n",
      "Total params: 148,057\n",
      "Trainable params: 148,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(thai_characters), \n",
    "                           output_dim=200, \n",
    "                           input_length=maxlen))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 15, 200)           13400     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 15, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 15, 112)           140224    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 15, 112)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 32)                18560     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 172,217\n",
      "Trainable params: 172,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(thai_characters), \n",
    "                           output_dim=200, \n",
    "                           input_length=maxlen))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(112, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2393 samples, validate on 599 samples\n",
      "Epoch 1/100\n",
      "2393/2393 [==============================] - 6s 2ms/step - loss: 0.6729 - acc: 0.5947 - val_loss: 0.5265 - val_acc: 0.7462\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52647, saving model to model-001-0.594651-0.746244-0.526466.h5\n",
      "Epoch 2/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.5337 - acc: 0.7392 - val_loss: 0.4610 - val_acc: 0.7863\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52647 to 0.46100, saving model to model-002-0.739239-0.786311-0.460995.h5\n",
      "Epoch 3/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4938 - acc: 0.7689 - val_loss: 0.4270 - val_acc: 0.7963\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46100 to 0.42695, saving model to model-003-0.768909-0.796327-0.426953.h5\n",
      "Epoch 4/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4757 - acc: 0.7840 - val_loss: 0.4176 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42695 to 0.41762, saving model to model-004-0.783953-0.813022-0.417625.h5\n",
      "Epoch 5/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4554 - acc: 0.7948 - val_loss: 0.4284 - val_acc: 0.7997\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41762\n",
      "Epoch 6/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4569 - acc: 0.7911 - val_loss: 0.4008 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41762 to 0.40076, saving model to model-006-0.791057-0.826377-0.400756.h5\n",
      "Epoch 7/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4385 - acc: 0.7990 - val_loss: 0.3961 - val_acc: 0.8114\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.40076 to 0.39608, saving model to model-007-0.798997-0.811352-0.396079.h5\n",
      "Epoch 8/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4398 - acc: 0.8028 - val_loss: 0.4013 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.39608\n",
      "Epoch 9/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4299 - acc: 0.8099 - val_loss: 0.3850 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.39608 to 0.38504, saving model to model-009-0.809862-0.844741-0.385039.h5\n",
      "Epoch 10/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4294 - acc: 0.8124 - val_loss: 0.3842 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38504 to 0.38416, saving model to model-010-0.812369-0.843072-0.384164.h5\n",
      "Epoch 11/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4230 - acc: 0.8115 - val_loss: 0.3868 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.38416\n",
      "Epoch 12/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4239 - acc: 0.8044 - val_loss: 0.3772 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.38416 to 0.37720, saving model to model-012-0.804430-0.834725-0.377196.h5\n",
      "Epoch 13/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4164 - acc: 0.8182 - val_loss: 0.3719 - val_acc: 0.8397\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.37720 to 0.37188, saving model to model-013-0.818220-0.839733-0.371883.h5\n",
      "Epoch 14/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4083 - acc: 0.8157 - val_loss: 0.3879 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.37188\n",
      "Epoch 15/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4108 - acc: 0.8211 - val_loss: 0.3958 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.37188\n",
      "Epoch 16/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4061 - acc: 0.8170 - val_loss: 0.3688 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.37188 to 0.36885, saving model to model-016-0.816966-0.831386-0.368846.h5\n",
      "Epoch 17/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.4022 - acc: 0.8211 - val_loss: 0.3860 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.36885\n",
      "Epoch 18/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3988 - acc: 0.8270 - val_loss: 0.3665 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.36885 to 0.36648, saving model to model-018-0.826995-0.836394-0.366476.h5\n",
      "Epoch 19/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3917 - acc: 0.8282 - val_loss: 0.3578 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.36648 to 0.35784, saving model to model-019-0.828249-0.838063-0.357844.h5\n",
      "Epoch 20/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3856 - acc: 0.8312 - val_loss: 0.3675 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.35784\n",
      "Epoch 21/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3765 - acc: 0.8354 - val_loss: 0.3630 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.35784\n",
      "Epoch 22/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3767 - acc: 0.8425 - val_loss: 0.3615 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.35784\n",
      "Epoch 23/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3824 - acc: 0.8362 - val_loss: 0.3674 - val_acc: 0.8464\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.35784\n",
      "Epoch 24/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3493 - acc: 0.8458 - val_loss: 0.3773 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.35784\n",
      "Epoch 25/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3568 - acc: 0.8387 - val_loss: 0.3747 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.35784\n",
      "Epoch 26/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3464 - acc: 0.8500 - val_loss: 0.3481 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.35784 to 0.34807, saving model to model-026-0.849979-0.851419-0.348067.h5\n",
      "Epoch 27/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3567 - acc: 0.8508 - val_loss: 0.3486 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34807\n",
      "Epoch 28/100\n",
      "2393/2393 [==============================] - 4s 2ms/step - loss: 0.3384 - acc: 0.8529 - val_loss: 0.3639 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34807\n",
      "Epoch 29/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3413 - acc: 0.8537 - val_loss: 0.3587 - val_acc: 0.8631\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34807\n",
      "Epoch 30/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3275 - acc: 0.8558 - val_loss: 0.3577 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34807\n",
      "Epoch 31/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3217 - acc: 0.8583 - val_loss: 0.3785 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34807\n",
      "Epoch 32/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3211 - acc: 0.8650 - val_loss: 0.3631 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34807\n",
      "Epoch 33/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3160 - acc: 0.8583 - val_loss: 0.3812 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34807\n",
      "Epoch 34/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3064 - acc: 0.8675 - val_loss: 0.3630 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34807\n",
      "Epoch 35/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3039 - acc: 0.8679 - val_loss: 0.3589 - val_acc: 0.8631\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34807\n",
      "Epoch 36/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3020 - acc: 0.8679 - val_loss: 0.3680 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34807\n",
      "Epoch 37/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.3027 - acc: 0.8696 - val_loss: 0.3631 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34807\n",
      "Epoch 38/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2934 - acc: 0.8792 - val_loss: 0.3662 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34807\n",
      "Epoch 39/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2814 - acc: 0.8834 - val_loss: 0.3730 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34807\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2740 - acc: 0.8826 - val_loss: 0.3851 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34807\n",
      "Epoch 41/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2786 - acc: 0.8859 - val_loss: 0.3780 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34807\n",
      "Epoch 42/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2682 - acc: 0.8888 - val_loss: 0.3793 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34807\n",
      "Epoch 43/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2540 - acc: 0.8951 - val_loss: 0.3865 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34807\n",
      "Epoch 44/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2602 - acc: 0.8888 - val_loss: 0.4026 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34807\n",
      "Epoch 45/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2550 - acc: 0.8926 - val_loss: 0.3974 - val_acc: 0.8414\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34807\n",
      "Epoch 46/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2572 - acc: 0.8826 - val_loss: 0.3979 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34807\n",
      "Epoch 47/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2467 - acc: 0.8993 - val_loss: 0.4048 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34807\n",
      "Epoch 48/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2537 - acc: 0.8939 - val_loss: 0.3959 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34807\n",
      "Epoch 49/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2433 - acc: 0.8959 - val_loss: 0.3907 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34807\n",
      "Epoch 50/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2446 - acc: 0.9005 - val_loss: 0.4049 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34807\n",
      "Epoch 51/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2312 - acc: 0.9005 - val_loss: 0.4320 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34807\n",
      "Epoch 52/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2380 - acc: 0.8985 - val_loss: 0.4146 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34807\n",
      "Epoch 53/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2310 - acc: 0.9018 - val_loss: 0.4182 - val_acc: 0.8397\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34807\n",
      "Epoch 54/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2245 - acc: 0.9056 - val_loss: 0.4499 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34807\n",
      "Epoch 55/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2257 - acc: 0.9051 - val_loss: 0.4296 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34807\n",
      "Epoch 56/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2086 - acc: 0.9139 - val_loss: 0.4473 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.34807\n",
      "Epoch 57/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2117 - acc: 0.9076 - val_loss: 0.4531 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34807\n",
      "Epoch 58/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2215 - acc: 0.9060 - val_loss: 0.4619 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34807\n",
      "Epoch 59/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2128 - acc: 0.9156 - val_loss: 0.4632 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34807\n",
      "Epoch 60/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2000 - acc: 0.9198 - val_loss: 0.4802 - val_acc: 0.8164\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34807\n",
      "Epoch 61/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1955 - acc: 0.9214 - val_loss: 0.5066 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34807\n",
      "Epoch 62/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1999 - acc: 0.9189 - val_loss: 0.4787 - val_acc: 0.8331\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34807\n",
      "Epoch 63/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1985 - acc: 0.9173 - val_loss: 0.4750 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.34807\n",
      "Epoch 64/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.2032 - acc: 0.9148 - val_loss: 0.4683 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.34807\n",
      "Epoch 65/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1975 - acc: 0.9122 - val_loss: 0.4820 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.34807\n",
      "Epoch 66/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1751 - acc: 0.9302 - val_loss: 0.5171 - val_acc: 0.8397\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.34807\n",
      "Epoch 67/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1884 - acc: 0.9235 - val_loss: 0.4888 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.34807\n",
      "Epoch 68/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1763 - acc: 0.9244 - val_loss: 0.4940 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.34807\n",
      "Epoch 69/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1727 - acc: 0.9281 - val_loss: 0.5152 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.34807\n",
      "Epoch 70/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1698 - acc: 0.9298 - val_loss: 0.5808 - val_acc: 0.8114\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.34807\n",
      "Epoch 71/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1726 - acc: 0.9298 - val_loss: 0.5300 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.34807\n",
      "Epoch 72/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1628 - acc: 0.9310 - val_loss: 0.5283 - val_acc: 0.8314\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.34807\n",
      "Epoch 73/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1439 - acc: 0.9415 - val_loss: 0.6126 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.34807\n",
      "Epoch 74/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1602 - acc: 0.9310 - val_loss: 0.5868 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.34807\n",
      "Epoch 75/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1522 - acc: 0.9365 - val_loss: 0.5717 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.34807\n",
      "Epoch 76/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1438 - acc: 0.9419 - val_loss: 0.5756 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.34807\n",
      "Epoch 77/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1570 - acc: 0.9323 - val_loss: 0.5683 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.34807\n",
      "Epoch 78/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1446 - acc: 0.9407 - val_loss: 0.6021 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.34807\n",
      "Epoch 79/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1430 - acc: 0.9394 - val_loss: 0.6043 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.34807\n",
      "Epoch 80/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1446 - acc: 0.9394 - val_loss: 0.5761 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.34807\n",
      "Epoch 81/100\n",
      "2393/2393 [==============================] - 4s 2ms/step - loss: 0.1526 - acc: 0.9373 - val_loss: 0.5896 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.34807\n",
      "Epoch 82/100\n",
      "2393/2393 [==============================] - 4s 2ms/step - loss: 0.1281 - acc: 0.9469 - val_loss: 0.6278 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.34807\n",
      "Epoch 83/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1361 - acc: 0.9394 - val_loss: 0.6241 - val_acc: 0.8180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00083: val_loss did not improve from 0.34807\n",
      "Epoch 84/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1316 - acc: 0.9444 - val_loss: 0.6544 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.34807\n",
      "Epoch 85/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1203 - acc: 0.9532 - val_loss: 0.6549 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.34807\n",
      "Epoch 86/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1203 - acc: 0.9490 - val_loss: 0.6702 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.34807\n",
      "Epoch 87/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1318 - acc: 0.9478 - val_loss: 0.6843 - val_acc: 0.8247\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.34807\n",
      "Epoch 88/100\n",
      "2393/2393 [==============================] - 3s 1ms/step - loss: 0.1392 - acc: 0.9440 - val_loss: 0.6272 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.34807\n",
      "Epoch 89/100\n",
      "2112/2393 [=========================>....] - ETA: 0s - loss: 0.1201 - acc: 0.9498"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-37784ebe505e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model-{epoch:03d}-{acc:03f}-{val_acc:03f}-{val_loss:03f}.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}-{val_loss:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748/748 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39844237913422403, 0.84625668481072]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model-026-0.849979-0.851419-0.348067.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ประยุทธ์', 'ประวิตร']\n",
    "results = model.predict(pad_sequences(list(map(get_name_indices, names)), padding='post', maxlen=maxlen))\n",
    "result_1d = results.reshape(results.shape[0])\n",
    "result_names = np.around(result_1d, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ประยุทธ์: Male | 0.988\n",
      "ประวิตร: Male | 0.796\n"
     ]
    }
   ],
   "source": [
    "labels = ['Female', 'Male']\n",
    "result_males = []\n",
    "result_females = []\n",
    "for i, name in enumerate(names):\n",
    "    result_class = int(result_names[i] > 0.5)\n",
    "    print('{}: {} | {:.3f}'.format(name, labels[result_class], result_names[i]))\n",
    "    \n",
    "    if result_class == 0:\n",
    "        result_females.append(name)\n",
    "    else:\n",
    "        result_males.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
